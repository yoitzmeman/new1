mapper.py

import sys

for line in sys.stdin:
    line = line.strip()
    columns = line.split('\t')
    salary= columns[2]
    print("%s\t%s" % (None, salary))


reducer.py

import sys

max_salary = 0

for line in sys.stdin:
    key, value = line.strip().split('\t', 1)
    try:
        salary= int(value)
    except ValueError:
        continue
    if salary > max_salary:
        max_salary= salary

print("Max Salary: %s" % max_salary)


input.txt

Alice Engineering   75000
Bob Sales   60000
Charlie Engineering 85000
David Sales 45000
Eve Marketing   90000
Frank Engineering   100000

$cat input.txt | python3 mapper.py | sort | python3 reducer.py

1. sudo su hduser
2. start-dfs.sh
3. start-yarn.sh
4. jps
5. hdfs dfs -put /input.txt /
6. hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming 3.3.4.jar -files
./mapper.py,./reducer.py -mapper "python3 mapper.py" -reducer "python3 reducer.py" -input
/5000-8.txt -output /0000009
7. Observe the result in localhost:9870
8. Download outputfile and view it for wordcount